{
  "hash": "e8c16d5c946f8dbdb311013a47a51c9b",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"What is the goal of this meta-analysis?\"\ndescription: \"Can always find something positive if you look hard enough\"\nauthor:\n  - name: Jay Brophy\n    url: https://brophyj.github.io/\n    orcid: 0000-0001-8049-6875\n    affiliation: McGill University Dept Medince, Epidemiology & Biostatistics\n    affiliation-url: https://mcgill.ca \ntags: []\ncategories: [meta-analysis, bias]\nimage: preview-image.jpg\ncitation: \n  url: https://brophyj.com/posts/2025-06-29-my-blog-post/ \ndate: 2025-11-27T14:39:55-05:00\nlastmod: 2025-11-27T14:39:55-05:00\nfeatured: true\ndraft: false\n# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.\nprojects: []\nformat:\n  html:\n    code-fold: true\n    code-tools: true   # optional: adds copy/download buttons\neditor_options: \n  markdown: \n    wrap: sentence\nbibliography: [bib.bib]\nbiblio-style: apalike\n---\n\n## Recent article - Background\nA recent meta-analysis[@RN2] concluded “Males with high-volume exercise training (>3,000 MET-min/wk) exhibited a higher burden of calcified plaque by CAC score than male nonathletes, while no such difference was observed in female athletes.” Apart from the surprising observation of a positive association of increased exercise and increased cardiovascular risk factors, one is left wondering what was the original objective of this study. Perhaps a look at the pre-registered protocol (https://www.crd.york.ac.uk/PROSPERO/view/CRD42024573617) can help. Here the main outcome is stated\n\n> The primary outcome of interest was analysis of coronary artery calcium (CAC) score (between athletes and non-athletes). \n\nThere is no mention of preplanned analyses according to sex of either the primary or any secondary outcome. Of course, results from post hoc analyses carry less inferential validity.      \n\nEven ignoring the apparent post hoc nature of the analysis, how should these results be interpreted? How can they be sensibly interpreted without an idea of the prior probability that women would behave differently than men or that heavy exercising men would behave worse than moderately exercising men?    \nEven ignoring the lack of prior probabilities, does the data show as contended by the authors that  male athletes engaging in high-volume exercise compared to nonathletes have higher CAC scores than athletes with moderate volume exercise compared to nonathletes. The CAC values for male athletes compared to nonathletes was 1.2 (95% CI -24.66 to 27.05, p = 0.9) for < 3000 group and 31.62 (95% 10.66 to 52.58, p = 0.003) for group > 3000. Are these differences statistically significant? \n\n\nThe fallacy of simply comparing significance levels has been well described  in several publications [@RN7649; @RN5623]. Testing for the statistical significance of the difference between two independent estimates is required to determine if they are statistically different and is easily implemented by calculating the risk difference and its confidence interval and p-value, as shown in the following code.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n###############\n# Interaction test for risk ratio RR\n###############\n\ninter_test <- function(rr1, rr1LL, rr1UL, rr2, rr2LL, rr2UL, sig=0.975) {\n  logSE1 <- abs(log(rr1UL) - log(rr1LL))/(2 * qnorm(sig)) #se of log(rr1), default 95%CI, sig = 1 sided value\n  logSE2 <- abs(log(rr2UL) - log(rr2LL))/(2 * qnorm(sig)) #se of log(rr1)\n  diffLogRR <- log(rr1) - log(rr2) #diff of log rr\n  logRR_SE <- sqrt(logSE1^2 + logSE2^2) #log (se) of differences\n  logRR_UCI <- diffLogRR + qnorm(sig) * logRR_SE\n  logRR_LCI <- diffLogRR - qnorm(sig) * logRR_SE\n  RR <- exp(diffLogRR) # RR point estimate\n  RR_UCI <- exp(logRR_UCI) # RR upper CI\n  RR_LCI <- exp(logRR_LCI) # RR lower CI\n  RR_SE <- (RR_UCI - RR_LCI) / (2*1.96)\n  z <- diffLogRR / logRR_SE\n  pvalue <- 2*(1-pnorm(abs(z))) #p value for the interaction term\n  state1 <- cat(\"The relative risk for the interaction is \", RR, \", 95% CI \", RR_LCI, \" - \", RR_UCI, \" and p value =\" , pvalue)\n}\n\n###############\n# Interaction test for risk difference #\n###############\n\ninter_test_rd <- function(rd1, rd1LL, rd1UL, rd2, rd2LL, rd2UL, sig=0.975) {\n  se1 <- abs(rd1UL - rd1LL)/(2 * qnorm(sig)) #se of risk difference 1\n  se2 <- abs(rd2UL - rd2LL)/(2 * qnorm(sig)) #se of risk difference 2\n  diffRD <- rd1 - rd2 #diff of risk difference\n  RD_SE <- sqrt(se1^2 + se2^2) #se of differences\n  RD_UCI <- diffRD + qnorm(sig) * RD_SE\n  RD_LCI <- diffRD - qnorm(sig) * RD_SE\n  pvalue <- 2*(1-pnorm(abs(diffRD/RD_SE))) #p value for the interaction term\n  # cat(\"The risk difference for the interaction is \", diffRD, \", 95% CI \", RD_LCI, \" - \", RD_UCI, \" and p value =\" , pvalue)\n  list(diffRD = diffRD, RD_LCI = RD_LCI, RD_UCI = RD_UCI, pvalue = pvalue)\n}\n\n\nrd_out <- inter_test_rd(1.2, -24.66, 27.05, 31.62, 10.66, 52.58)\n```\n:::\n\n\n\nThe risk difference for the interaction is  -30.42, (95% CI  -63.7 to 2.86,  p = 0.07). The key insight being “In making a comparison between two group, one should look at the statistical significance of the difference rather than the difference between their significance levels”[@RN7649]. Thus, there is no statistical evidence of a difference in CAC values between male athletes engaging in high-volume exercise compared to nonathletes and male athletes with moderate volume exercise compared to nonathletes. This becomes more evident if the forest plots (Bayesian with vague priors) are recreated with the prediction intervals showing the considerable overalp in the predcited next study for the subgroups.\n\n::: {.cell}\n\n```{.r .cell-code}\n# men\n# ---- Packages ----\nlibrary(tidyverse)\nlibrary(brms)\nlibrary(tidybayes)\nlibrary(cmdstanr)\n\noptions(mc.cores = parallel::detectCores())\n\n# ---- Data (extracted from your figure) ----\ndf <- tribble(\n  ~group,        ~study,               ~yi,   ~lower,   ~upper,\n  \"1500-3000\",   \"Aengevaeren 2017\",   11.50,   2.92,   20.08,\n  \"1500-3000\",   \"Pavlovic 2024\",      16.50,  -0.16,   33.16,\n  \"1500-3000\",   \"Defina 2019\",       -27.12, -47.05,   -6.99,\n  \">3000\",       \"Bosscher 2023\",      19.80,   8.84,   30.76,\n  \">3000\",       \"Mohlenkamp 2008\",     9.08, -18.88,   37.04,\n  \">3000\",       \"Pavlovic 2024\",      25.06,  13.55,   37.57,\n  \">3000\",       \"Defina 2019\",        42.50,  12.08,   72.92\n) %>%\n  mutate(\n    sei = (upper - lower) / (2 * 1.96),\n    study = factor(study),\n    group = factor(group, levels = c(\"1500-3000\", \">3000\")) # explicit subgroup order\n  )\n\n# ---- Priors: vague but weakly informative ----\npriors <- c(\n  prior(normal(0, 50), class = \"Intercept\"),              # mu ~ N(0, 50^2)\n  prior(student_t(3, 0, 10), class = \"sd\", group = \"study\")# tau ~ t(3,0,10)\n)\n\n# ---- Fit models ----\nfit_all <- brm(yi | se(sei) ~ 1 + (1 | study),\n               data = df, family = gaussian(),\n               prior = priors, backend = \"cmdstanr\",\n               iter = 4000, chains = 4, seed = 123)\n\n# Save the model object to disk\nsaveRDS(fit_all, file = \"model/fit_all.rds\")\n\n\nfit_1500 <- brm(yi | se(sei) ~ 1 + (1 | study),\n                data = dplyr::filter(df, group == \"1500-3000\"),\n                family = gaussian(), prior = priors,\n                backend = \"cmdstanr\", iter = 4000, chains = 4, seed = 123)\nsaveRDS(fit_all, file = \"model/fit_1500.rds\")\n\nfit_3000 <- brm(yi | se(sei) ~ 1 + (1 | study),\n                data = dplyr::filter(df, group == \">3000\"),\n                family = gaussian(), prior = priors,\n                backend = \"cmdstanr\", iter = 4000, chains = 4, seed = 123)\nsaveRDS(fit_all, file = \"model/fit_3000.rds\")\n\n# ---- Posterior draws ----\ndraws_all <- fit_all %>% spread_draws(b_Intercept, sd_study__Intercept)\ndraws_1   <- fit_1500 %>% spread_draws(b_Intercept, sd_study__Intercept)\ndraws_2   <- fit_3000 %>% spread_draws(b_Intercept, sd_study__Intercept)\n\n# ---- Summaries (μ and τ) ----\nsummarise_mu_tau <- function(dr) {\n  tibble(\n    mu_median  = median(dr$b_Intercept),\n    mu_low     = quantile(dr$b_Intercept, 0.025),\n    mu_high    = quantile(dr$b_Intercept, 0.975),\n    tau_median = median(dr$sd_study__Intercept),\n    tau_low    = quantile(dr$sd_study__Intercept, 0.025),\n    tau_high   = quantile(dr$sd_study__Intercept, 0.975)\n  )\n}\nsumm_all <- summarise_mu_tau(draws_all)\nsumm_1   <- summarise_mu_tau(draws_1)\nsumm_2   <- summarise_mu_tau(draws_2)\n\n# ---- Prediction intervals (new TRUE study effect) ----\nsummarise_pred <- function(dr) {\n  theta_new <- dr$b_Intercept + rnorm(nrow(dr)) * dr$sd_study__Intercept\n  tibble(\n    pred_low  = quantile(theta_new, 0.025),\n    pred_high = quantile(theta_new, 0.975)\n  )\n}\npi_all <- summarise_pred(draws_all)\npi_1   <- summarise_pred(draws_1)\npi_2   <- summarise_pred(draws_2)\n\n# ---- Build plotting rows with exact order ----\n# Desired order from TOP to BOTTOM:\n# 1) Subgroup \"1500-3000\": its studies (top), then \"1500-3000 Pooled\", then \"1500-3000 Predicted\"\n#    then a GAP\n# 2) Subgroup \">3000\":     its studies, then \">3000 Pooled\", then \">3000 Predicted\"\n#    then a GAP\n# 3) Overall:              \"Overall Pooled\", then \"Overall Predicted\" (very bottom)\n\n# Helper to make study rows\nmake_study_rows <- function(dsub, label_group) {\n  dsub %>%\n    mutate(\n      lab   = paste0(study, \" (\", label_group, \")\"),\n      type  = \"study\",\n      xmin  = lower, x = yi, xmax = upper,\n      col   = \"#1f77b4\", shape = NA_real_\n    ) %>%\n    select(lab, type, xmin, x, xmax, col, shape)\n}\n\n# Helper to make pooled + predicted rows (in that order)\nmake_summary_rows <- function(summ, pi, label_group) {\n  pooled <- tibble(\n    lab   = paste0(label_group, \" Pooled\"),\n    type  = \"pooled\",\n    xmin  = summ$mu_low, x = summ$mu_median, xmax = summ$mu_high,\n    col   = \"darkred\", shape = 15\n  )\n  predicted <- tibble(\n    lab   = paste0(label_group, \" Predicted\"),\n    type  = \"predicted\",\n    xmin  = pi$pred_low, x = summ$mu_median, xmax = pi$pred_high,\n    col   = \"orange\", shape = 17\n  )\n  dplyr::bind_rows(pooled, predicted)\n}\n\nrows_top_to_bottom <- dplyr::bind_rows(\n  # Subgroup 1500–3000 block\n  make_study_rows(df %>% dplyr::filter(group == \"1500-3000\") %>% dplyr::arrange(dplyr::desc(study)), \"1500-3000\"),\n  make_summary_rows(summ_1, pi_1, \"1500-3000\"),\n  tibble(lab = \"\", type = \"gap\", xmin = NA, x = NA, xmax = NA, col = NA, shape = NA_real_),\n\n  # Subgroup >3000 block\n  make_study_rows(df %>% dplyr::filter(group == \">3000\") %>% dplyr::arrange(dplyr::desc(study)), \">3000\"),\n  make_summary_rows(summ_2, pi_2, \">3000\"),\n  tibble(lab = \"\", type = \"gap\", xmin = NA, x = NA, xmax = NA, col = NA, shape = NA_real_),\n\n  # Overall at very bottom: pooled then predicted\n  make_summary_rows(summ_all, pi_all, \"Overall\")\n)\n\nrows_top_to_bottom <- rows_top_to_bottom %>%\n  mutate(row_id = dplyr::row_number()) %>%\n  mutate(y = rev(row_id))\n\nlibrary(ggplot2)\n\np <- ggplot(rows_top_to_bottom, aes(y = y, x = x)) +\n  geom_errorbarh(data = dplyr::filter(rows_top_to_bottom, type == \"study\"),\n                 aes(xmin = xmin, xmax = xmax), height = 0.2,\n                 color = \"#1f77b4\") +\n  geom_point(data = dplyr::filter(rows_top_to_bottom, type == \"study\"),\n             color = \"#1f77b4\", size = 2) +\n  geom_errorbarh(data = dplyr::filter(rows_top_to_bottom, type == \"pooled\"),\n                 aes(xmin = xmin, xmax = xmax), height = 0.3,\n                 color = \"darkred\", size = 1.1) +\n  geom_point(data = dplyr::filter(rows_top_to_bottom, type == \"pooled\"),\n             aes(shape = factor(shape)), color = \"darkred\", size = 3) +\n  geom_errorbarh(data = dplyr::filter(rows_top_to_bottom, type == \"predicted\"),\n                 aes(xmin = xmin, xmax = xmax), height = 0.3,\n                 color = \"orange\", size = 1.1) +\n  geom_point(data = dplyr::filter(rows_top_to_bottom, type == \"predicted\"),\n             aes(shape = factor(shape)), color = \"orange\", size = 3) +\n  geom_vline(xintercept = 0, color = \"black\") +\n  geom_text(data = dplyr::filter(rows_top_to_bottom, type == \"pooled\"),\n            aes(x = xmax + 3, y = y, label = \"Pooled\"),\n            hjust = 0, size = 3.2) +\n  geom_text(data = dplyr::filter(rows_top_to_bottom, type == \"predicted\"),\n            aes(x = xmax + 3, y = y, label = \"Predicted\"),\n            hjust = 0, size = 3.2) +\n  scale_y_continuous(\n    breaks = rows_top_to_bottom$y,\n    labels = rows_top_to_bottom$lab\n  ) +\n  scale_shape_manual(values = c(`15` = 15, `17` = 17), guide = \"none\") +\n  labs(\n    x = \"Mean difference\", y = NULL,\n    title = \"Forest plot: CACs cores in male athletes engaging in different volumes of exercise\",\n    caption = \"Points and horizontal lines represent posterior medians and 95% credible intervals\") +\n  theme_minimal() +\n  theme(\n    axis.text.y = element_text(size = 9),\n    plot.title = element_text(size = 13, face = \"bold\")\n  )\n\n# Save plot\nggsave(\"images/male_forest_plot.png\", p, width = 7.5, height = 8.5, dpi = 300)\nggsave(\"images/male_forest_plot.pdf\", p, width = 7.5, height = 8.5)\n```\n:::\n\n\n![](images/male_forest_plot.png)\n\nWhat if the authors had followed their protocol and examined CAC scores in all athletes compared to nonathletes? \n\n::: {.cell}\n\n```{.r .cell-code}\n# ---- Packages ----\nlibrary(tidyverse)\nlibrary(brms)\nlibrary(tidybayes)\nlibrary(cmdstanr)\n\noptions(mc.cores = parallel::detectCores())\n\n# ---- Data (extracted from your figure) ----\n\n# ---- Data (COMBINED Male + Female) ----\n\n# ---- Data (COMBINED Male + Female, grouped) ----\n\ndf <- tribble(\n  ~group,        ~study,               ~yi,    ~lower,    ~upper,\n  \"1500-3000\",   \"Aengevaeren 2017\",   -1.75,  -13.54,    10.04,\n  \"1500-3000\",   \"Pavlovic 2024\",      13.25,   -2.58,    29.08,\n  \"1500-3000\",   \"Defina 2019\",       -23.56,  -43.53,    -3.50,\n  \">3000\",       \"Bosscher 2023\",      17.40,    4.42,    30.38,\n  \">3000\",       \"Mohlenkamp 2008\",     7.04,  -14.44,    28.52\n) %>%\n  mutate(\n    sei = (upper - lower) / (2 * 1.96),\n    study = factor(study),\n    group = factor(group, levels = c(\"1500-3000\", \">3000\"))\n  )\n\n    \n\n# ---- Priors: vague but weakly informative ----\npriors <- c(\n  prior(normal(0, 50), class = \"Intercept\"),              # mu ~ N(0, 50^2)\n  prior(student_t(3, 0, 10), class = \"sd\", group = \"study\")# tau ~ t(3,0,10)\n)\n\n# ---- Fit models ----\nfit_all <- brm(yi | se(sei) ~ 1 + (1 | study),\n               data = df, family = gaussian(),\n               prior = priors, backend = \"cmdstanr\", \n               iter = 4000, chains = 4, seed = 123, refresh = 0)\n\n# Save the model object to disk\nsaveRDS(fit_all, file = \"model/combined_all.rds\")\n\n\nfit_1500 <- brm(yi | se(sei) ~ 1 + (1 | study),\n                data = dplyr::filter(df, group == \"1500-3000\"),\n                family = gaussian(), prior = priors,\n                backend = \"cmdstanr\", iter = 4000, chains = 4, seed = 123, refresh = 0)\nsaveRDS(fit_all, file = \"model/combined_1500.rds\")\n\nfit_3000 <- brm(yi | se(sei) ~ 1 + (1 | study),\n                data = dplyr::filter(df, group == \">3000\"),\n                family = gaussian(), prior = priors,\n                backend = \"cmdstanr\", iter = 4000, chains = 4, refresh = 0, seed = 123)\nsaveRDS(fit_all, file = \"model/combined_3000.rds\")\n\nfit_all <- readRDS(\"model/combined_all.rds\")\nfit_1500 <- readRDS(\"model/combined_1500.rds\")\nfit_3000 <- readRDS(\"model/combined_3000.rds\")\n\n# ---- Posterior draws ----\ndraws_all <- fit_all %>% spread_draws(b_Intercept, sd_study__Intercept)\ndraws_1   <- fit_1500 %>% spread_draws(b_Intercept, sd_study__Intercept)\ndraws_2   <- fit_3000 %>% spread_draws(b_Intercept, sd_study__Intercept)\n\n# ---- Summaries (μ and τ) ----\nsummarise_mu_tau <- function(dr) {\n  tibble(\n    mu_median  = median(dr$b_Intercept),\n    mu_low     = quantile(dr$b_Intercept, 0.025),\n    mu_high    = quantile(dr$b_Intercept, 0.975),\n    tau_median = median(dr$sd_study__Intercept),\n    tau_low    = quantile(dr$sd_study__Intercept, 0.025),\n    tau_high   = quantile(dr$sd_study__Intercept, 0.975)\n  )\n}\nsumm_all <- summarise_mu_tau(draws_all)\nsumm_1   <- summarise_mu_tau(draws_1)\nsumm_2   <- summarise_mu_tau(draws_2)\n\n# ---- Prediction intervals (new TRUE study effect) ----\nsummarise_pred <- function(dr) {\n  theta_new <- dr$b_Intercept + rnorm(nrow(dr)) * dr$sd_study__Intercept\n  tibble(\n    pred_low  = quantile(theta_new, 0.025),\n    pred_high = quantile(theta_new, 0.975)\n  )\n}\npi_all <- summarise_pred(draws_all)\npi_1   <- summarise_pred(draws_1)\npi_2   <- summarise_pred(draws_2)\n\n# ---- Build plotting rows with exact order ----\n# Desired order from TOP to BOTTOM:\n# 1) Subgroup \"1500-3000\": its studies (top), then \"1500-3000 Pooled\", then \"1500-3000 Predicted\"\n#    then a GAP\n# 2) Subgroup \">3000\":     its studies, then \">3000 Pooled\", then \">3000 Predicted\"\n#    then a GAP\n# 3) Overall:              \"Overall Pooled\", then \"Overall Predicted\" (very bottom)\n\n# Helper to make study rows\nmake_study_rows <- function(dsub, label_group) {\n  dsub %>%\n    mutate(\n      lab   = paste0(study, \" (\", label_group, \")\"),\n      type  = \"study\",\n      xmin  = lower, x = yi, xmax = upper,\n      col   = \"#1f77b4\", shape = NA_real_\n    ) %>%\n    select(lab, type, xmin, x, xmax, col, shape)\n}\n\n# Helper to make pooled + predicted rows (in that order)\nmake_summary_rows <- function(summ, pi, label_group) {\n  pooled <- tibble(\n    lab   = paste0(label_group, \" Pooled\"),\n    type  = \"pooled\",\n    xmin  = summ$mu_low, x = summ$mu_median, xmax = summ$mu_high,\n    col   = \"darkred\", shape = 15\n  )\n  predicted <- tibble(\n    lab   = paste0(label_group, \" Predicted\"),\n    type  = \"predicted\",\n    xmin  = pi$pred_low, x = summ$mu_median, xmax = pi$pred_high,\n    col   = \"orange\", shape = 17\n  )\n  dplyr::bind_rows(pooled, predicted)\n}\n\nrows_top_to_bottom <- dplyr::bind_rows(\n  # Subgroup 1500–3000 block\n  make_study_rows(df %>% dplyr::filter(group == \"1500-3000\") %>% dplyr::arrange(dplyr::desc(study)), \"1500-3000\"),\n  make_summary_rows(summ_1, pi_1, \"1500-3000\"),\n  tibble(lab = \"\", type = \"gap\", xmin = NA, x = NA, xmax = NA, col = NA, shape = NA_real_),\n  \n  # Subgroup >3000 block\n  make_study_rows(df %>% dplyr::filter(group == \">3000\") %>% dplyr::arrange(dplyr::desc(study)), \">3000\"),\n  make_summary_rows(summ_2, pi_2, \">3000\"),\n  tibble(lab = \"\", type = \"gap\", xmin = NA, x = NA, xmax = NA, col = NA, shape = NA_real_),\n  \n  # Overall at very bottom: pooled then predicted\n  make_summary_rows(summ_all, pi_all, \"Overall\")\n)\n\nrows_top_to_bottom <- rows_top_to_bottom %>%\n  mutate(row_id = dplyr::row_number()) %>%\n  mutate(y = rev(row_id))\n\nlibrary(ggplot2)\n\np <- ggplot(rows_top_to_bottom, aes(y = y, x = x)) +\n  geom_errorbarh(data = dplyr::filter(rows_top_to_bottom, type == \"study\"),\n                 aes(xmin = xmin, xmax = xmax), height = 0.2,\n                 color = \"#1f77b4\") +\n  geom_point(data = dplyr::filter(rows_top_to_bottom, type == \"study\"),\n             color = \"#1f77b4\", size = 2) +\n  geom_errorbarh(data = dplyr::filter(rows_top_to_bottom, type == \"pooled\"),\n                 aes(xmin = xmin, xmax = xmax), height = 0.3,\n                 color = \"darkred\", size = 1.1) +\n  geom_point(data = dplyr::filter(rows_top_to_bottom, type == \"pooled\"),\n             aes(shape = factor(shape)), color = \"darkred\", size = 3) +\n  geom_errorbarh(data = dplyr::filter(rows_top_to_bottom, type == \"predicted\"),\n                 aes(xmin = xmin, xmax = xmax), height = 0.3,\n                 color = \"orange\", size = 1.1) +\n  geom_point(data = dplyr::filter(rows_top_to_bottom, type == \"predicted\"),\n             aes(shape = factor(shape)), color = \"orange\", size = 3) +\n  geom_vline(xintercept = 0, color = \"black\") +\n  geom_text(data = dplyr::filter(rows_top_to_bottom, type == \"pooled\"),\n            aes(x = xmax + 3, y = y, label = \"Pooled\"),\n            hjust = 0, size = 3.2) +\n  geom_text(data = dplyr::filter(rows_top_to_bottom, type == \"predicted\"),\n            aes(x = xmax + 3, y = y, label = \"Predicted\"),\n            hjust = 0, size = 3.2) +\n  scale_y_continuous(\n    breaks = rows_top_to_bottom$y,\n    labels = rows_top_to_bottom$lab\n  ) +\n  scale_shape_manual(values = c(`15` = 15, `17` = 17), guide = \"none\") +\n  labs(\n    x = \"Mean difference\", y = NULL,\n    title = \"Forest plot: CACs cores in male & female athletes engaging in different volumes of exercise\",\n    caption = \"Points and horizontal lines represent posterior medians and 95% credible intervals\") +\n  theme_minimal() +\n  theme(\n    axis.text.y = element_text(size = 9),\n    plot.title = element_text(size = 13, face = \"bold\")\n  )\n\n# Save plot\nggsave(\"images/combined_forest_plot.png\", p, width = 7.5, height = 8.5, dpi = 300)\nggsave(\"images/combined_forest_plot.pdf\", p, width = 7.5, height = 8.5)\n```\n:::\n\n\n![](images/combined_forest_plot.png)\nThe plot shows mean difference = 3.6 (95% CI -10.3 to 16.5), with no evidence of a statistically significant difference.\n\n## Conclusion\nThe original objective of the meta-analysis was to compare CAC scores in athletes versus nonathletes and while not reported in the final publication, this showed no meaningful differences. The authors reported only post hoc analyses according to sex and claim that \"males with high-volume exercise training (>3,000 MET-min/wk) exhibited a higher burden of calcified plaque by CAC score than male nonathletes\". This is somewhat disengenous as there was no difference between lower level exercise training (1,500 - 3,000 MET-min/wk) and calcified plaque by CAC score compared to male nonathletes, nor was there any statistically significant difference when comparing the high amd low groups.       \n\nIt is well known that positive results have a higher probability of being published and a cynical reader might wonder if the authors, aware of this, were simply looking for anything positive, or at least trending to positive, to report and found it by examining subgroups according to sex and level of exercise training. This is known as p-hacking, although the proper analysis did not find a statistically significant p value, and is a well recognized source of bias in the scientific literature.     \n\nDeviations from the preregistered protocol, ignoring prior evidence  of exercise benefits, and questionable statistical analyses weaken any  possible useful inferences from this study. What then is the legacy of the publication beyond adding to the authors' CVs?\n\n## References\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}