{
  "hash": "4ed7de6c31685c242803ecded50e20d1",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Understanding unexpected results from randomized clini\\u2060cal trials\"\ndescription: \"Does coffee reduce atrial fibrillation recurrences?\"\nauthor:\n  - name: Jay Brophy\n    url: https://brophyj.github.io/\n    orcid: 0000-0001-8049-6875\n    affiliation: McGill University Dept Medince, Epidemiology & Biostatistics\n    affiliation-url: https://mcgill.ca \ntags: []\ncategories: [RCT, bias, Bayesian]\nimage: preview-image.jpg\ncitation: \n  url: https://brophyj.com/posts/2025-12-04-my-blog-post/ \ndate: 2025-12-04T14:39:55-05:00\nlastmod: 2025-12-04T14:39:55-05:00\nfeatured: true\ndraft: false\n# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.\nprojects: []\nformat:\n  html:\n    code-fold: true\n    code-tools: true   # optional: adds copy/download buttons\n    keep_md: true\n    self_contained: true\neditor_options: \n  markdown: \n    wrap: sentence\nbibliography: [bib.bib]\nbiblio-style: apalike\n---\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# load required packages\nsuppressPackageStartupMessages({\n  library(brms)        # Bayesian GLMs via Stan\n  library(cmdstanr)    # backend for brms\n  library(posterior)   # tidy posterior draws\n  library(bayesplot)   # PPC & MCMC visualization\n  library(ggplot2)\n  library(scales)  \n  library(tidybayes)   # for bayesian plotting / functions\n  library(bridgesampling)\n  library(knitr)\n  library(rstanarm)\n  library(readr)\n  library(dplyr)\n  library(tidyr)\n  library(survival)\n  library(survminer)\n  library(IPDfromKM)\n})\n\n# Use cmdstanr backend (faster, fewer divergences)\ncmdstanr::set_cmdstan_path()\noptions(mc.cores = max(1, parallel::detectCores() - 1))\n\nsuppressMessages(cmdstanr::set_cmdstan_path())\n\n\n\n# Optional: make figures a bit crisper\nbayesplot::color_scheme_set(\"teal\")\n\n# suppress brms startup messages\n\n#| label: quiet-brms-helpers\n#| include: false\n\n`%||%` <- function(x, y) if (!is.null(x)) x else y\n\nquiet_brms <- function(...,\n                       backend_args = NULL,\n                       quiet = TRUE,\n                       noisy_on_error = TRUE,\n                       debug = getOption(\"quiet_brms.debug\", FALSE)) {\n  # Merge backend_args with a 'quiet' flag (caller args win)\n  backend_args <- utils::modifyList(list(quiet = quiet), backend_args %||% list())\n  \n  run <- function(q) {\n    # Rebuild backend_args with desired quiet setting for this run\n    ba <- utils::modifyList(backend_args, list(quiet = q))\n    brms::brm(..., backend = \"cmdstanr\", backend_args = ba)\n  }\n  \n  # If user forces debug, run noisily and return (shows full compiler output)\n  if (isTRUE(debug)) {\n    message(\"[quiet_brms] Debug mode: running noisily.\")\n    return(run(FALSE))\n  }\n  \n  # Try a quiet run, suppressing R warnings/messages (compiler output minimized by quiet=TRUE)\n  fit <- NULL\n  err <- NULL\n  fit <- try(\n    suppressWarnings(\n      suppressMessages(\n        run(TRUE)\n      )\n    ),\n    silent = TRUE\n  )\n  \n  if (inherits(fit, \"try-error\")) {\n    if (isTRUE(noisy_on_error)) {\n      # Surface the *real* cause: re-run noisily so cmdstanr/clang++ errors are printed\n      message(\"\\n[quiet_brms] Quiet run failed. Re-running noisily to show the compiler error...\\n\")\n      return(run(FALSE))  # If this errors, you will see the full compiler/Stan error\n    } else {\n      stop(attr(fit, \"condition\") %||% fit)\n    }\n  }\n  \n  fit\n}\n\nquiet_brms <- function(...) {\n  model <- NULL\n  invisible(capture.output({\n    model <- brm(...)\n  }))\n  return(model)\n}\n\n\n#| label: setup-defaults\n#| include: false\n# Hide code everywhere by default\nknitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)\n\n# Re-enable code ONLY for HTML output (so HTML keeps code-fold etc.)\nif (knitr::is_html_output()) {\n  knitr::opts_chunk$set(echo = TRUE)\n}\n```\n:::\n\n\n\n## Backgound\n\nA recent paper, [\"Caffeinated Coffee Consumption or Abstinence to Reduce Atrial Fibrillation The DECAF Randomized Clinical Trial\"](https://jamanetwork.com/journals/jama/fullarticle/2841253)[@RN1] published online in JAMA on Nov 9 2025 concluded\n\n> \"In this clinical trial of coffee drinkers after successful cardioversion, allocation to consumption of caffeinated coffee averaging 1 cup a day was associated with less recurrence of AF or atrial flutter compared with abstinence from coffee and caffeinated products.\"\\\n\nThis conclusion is likely surprising to most physicians as the historical belief is that caffeine is associated with increased cardiac ectopy.\nHowever the authors make the case that while \n\n> \"Caffeinated coffee has traditionally been considered proarrhythmic\"\n\nits role in atrial fibrillation is less uncertain. Supporting this uncertainty, the authors refer to a previous randomized trial[@RN3] that was not of atrial fibrillation patients but rather of 100 ambulatory patients studies in a crossover design.\nThat study concluded\n\n> \" the consumption of caffeinated coffee did not result in significantly more daily premature atrial contractions than the avoidance of caffeine\"\n\nThis small trial[@RN3] examined only short-term surrogate endpoints, not atrial fibrillation outcomes, and actually found a non significant trend towards more atrial ectopy in the caffeine group.      \n\n> \"The consumption of caffeinated coffee was associated with 58 daily premature atrial contractions as compared with 53 daily events on days when caffeine was avoided (rate ratio, 1.09; 95% confidence interval [CI], 0.98 to 1.20; P=0.10). The consumption of caffeinated coffee as compared with no caffeine consumption was associated with 154 and 102 daily premature ventricular contractions, respectively (rate ratio, 1.51; 95% CI, 1.18 to 1.94).\"[@RN3]\n\n\nApart from assuming that atrial ectopy is a good surrogate for atrial fibrillation, this suggests confusion between \"absence of evidence\" with \"evidence of absence\".    \n\nThe DECAF authors[@RN1] also cite a meta-analysis of 12 observational studies[@RN4] that reported no conclusive evidence for or against an association between caffeine intake and incident atrial fibrillation (OR 0.95 (0.84–1.06). The quality of these 12 studies was not reported and as the DECAF authors state \n\n> \"observational studies are prone to confounding,and whether these findings are biased by systematic differences between coffee and noncoffee drinkers is unclear\"[@RN1]    \n\nGiven this uncertainty, DECAF[@RN1] was designed to investigate the effect of caffeinated coffee consumption versus abstinence on atrial fibrillation recurrence following successful cardioversion. \n\n## DECAF Trial Design \n\nDECAF[@RN1] was a randomized controlled trial of 200 regular coffee drinkers with a recent successful cardioversion for atrial fibrillation (AF). Patients were randomized to either continue their usual caffeinated coffee consumption (median 1 cup/day) or to abstain from all caffeine products (decaf group). The primary outcome was recurrence of atrial fibrillation or atrial flutter within 6 months. The sample size calculations were based on assuming     \n\n> \"... a 50% incidence of AF recurrence within 6 months following cardioversion. A clinically relevant effect size was assumed to approximate the effectiveness of commonly prescribed antiarrhythmic drugs for recurrentAFafter cardioversion. To provide 80% power\nto detect a minimum 41% reduced relative hazard of AF, we enrolled 200 patients (100 per group) assuming a 1:1 randomization scheme, potential 10% loss to follow-up, and .05 2-tailed α level.\"[@RN1]     \n\nThis description is problematic for the following reasons.       \n1. The implication is, since the methods section is written before any results are available, that 1:1 randomization of 200 subjects will automatically produce two equal groups. Based on binomial probability theory, there is only a 5.7% chance of achieving a perfectly balanced split (see Figure below).  \n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset.seed(123)\nnrand <- rbinom(20000, 200, 0.5)\ndf <- data.frame(nrand = nrand)\n\n# Count for x = 100\ncount_100 <- sum(nrand == 100)\n\n# Theoretical probabilities for overlay\nx_vals <- 80:120\ntheoretical <- data.frame(\n  x = x_vals,\n  prob = dbinom(x_vals, size = 200, prob = 0.5) * 20000\n)\n\ngg1 <- ggplot(df, aes(x = nrand, fill = nrand == 100)) +\n  geom_histogram(binwidth = 1, color = \"black\") +\n  scale_fill_manual(values = c(\"TRUE\" = \"red\", \"FALSE\" = \"lightblue\")) +\n  geom_line(data = theoretical, aes(x = x, y = prob),\n            color = \"darkblue\", linewidth = 1.2, inherit.aes = FALSE) +\n  annotate(\"text\", x = 100, y = count_100 + 50,\n           label = paste(\"Count =\", count_100, \"\\n= \", round((count_100 / 20000) * 100, 2), \"%\", sep = \"\"),\n           color = \"red\", fontface = \"bold\") +\n  labs(\n    title = \"Histogram of 20,000 Simulations \\nDrawn from Binomial(200, 0.5)\",\n    x = \"Number per group\",\n    y = \"Frequency\",\n    caption = \"Red bar indicates count at x = 100 \\nBlue line represents theoretical probabilities\"\n  ) +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\nprint(gg1)\nggsave(\"output/binom_group_sizes.png\", gg1, width = 7, height = 5, dpi = 300)\n```\n:::\n\n  \n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Histogram of 20,000 simulations drawn from Binomical (200, 0.5)](output/binom_group_sizes.png){fig-align='center' width=600px}\n:::\n:::\n\n \n2. Given the prevailing prior uncertainty, designing a trial to detect a very large risk reduction is overly optimistic. The 80% power estimate assumed a 41% reduction applied to a 50% baseline rates, meaning the intervention is expected to reduce recurrence by an absolute 20.5%. What would be the power with this sample size of 200 to detect a more modest relative risk reduction, say 15% (i.e. from 50% to 42.5%)? The answer is 24% (see Figure below, left panel), illustrating the study was severely underpowered to detect more realistic effect sizes and therefore at risk of Type M (magnitude) error[@RN38], meaning  any statistically significant result tends to exaggerate the true effect[@RN38]. Thus the observed −17% risk difference may be overstating the true benefit, possibly by a factor of two (see right panel of above Figure). The published result should therefore be interpreted cautiously. Further exploration of the probability of a clinically meaningful result awaits the Bayesian analysis provided in later sections.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# ----------------------------------------\n# Required packages\n# ----------------------------------------\nlibrary(retrodesign)\nlibrary(ggplot2)\nlibrary(patchwork)\n\n# ----------------------------------------\n# Calculate SE from observed effect and CrI\n# ----------------------------------------\nobserved_effect <- -0.076     # Observed RD (Caf - Decaf)\nlower <- -0.195               # Lower bound of 95% CrI\nupper <- 0.044                # Upper bound of 95% CrI\n\n# Approximate SE from 95% CrI\nse <- (upper - lower) / (2 * 1.96)\n\n# z-score and p-value (frequentist approximation)\nz <- observed_effect / se\np_value <- 2 * (1 - pnorm(abs(z)))\n\n# ----------------------------------------\n# Assumed effect from original design\n# ----------------------------------------\nassumed_effect <- 0.20  # DECAF assumed a large benefit for decaf\n\n# ----------------------------------------\n# Compute retrodesign metrics for observed and assumed effects\n# ----------------------------------------\nretro_observed <- retro_design_closed_form(observed_effect, se)\nretro_assumed <- retro_design_closed_form(assumed_effect, se)\n\npower_observed <- retro_observed$power\npower_assumed <- retro_assumed$power\ntype_s_observed <- retro_observed$type_s\ntype_m_observed <- retro_observed$type_m\n\n# ----------------------------------------\n# Print numeric summary\n# ----------------------------------------\n# cat(\"Observed Effect =\", observed_effect, \"\\n\")\n# cat(\"SE =\", round(se, 4), \"\\n\")\n# cat(\"Approx p-value =\", round(p_value, 4), \"\\n\")\n# cat(\"Power (Observed) =\", round(power_observed, 3), \"\\n\")\n# cat(\"Type S Error =\", round(type_s_observed, 3), \"\\n\")\n# cat(\"Type M Error =\", round(type_m_observed, 3), \"\\n\\n\")\n# cat(\"Assumed Effect =\", assumed_effect, \"\\n\")\n# cat(\"Power (Assumed) =\", round(power_assumed, 3), \"\\n\\n\")\n\n\n# ----------------------------------------\n# Range of true effects for plotting\n# ----------------------------------------\ntrue_effects <- seq(-0.20, 0.20, length.out = 200)\nretro <- retro_design_closed_form(true_effects, se)\n\n# Build data frame\ndf <- data.frame(\n  TrueEffect = true_effects,\n  Power = retro$power,\n  TypeS = retro$type_s,\n  Exaggeration = retro$type_m\n)\n\n# ----------------------------------------\n# Custom theme for polished look\n# ----------------------------------------\ncustom_theme <- theme_minimal(base_size = 16) +\n  theme(\n    plot.title = element_text(face = \"bold\", size = 18),\n    plot.subtitle = element_text(size = 14),\n    axis.title = element_text(size = 14),\n    axis.text = element_text(size = 12),\n    panel.grid.minor = element_blank()\n  )\n\n# ----------------------------------------\n# Panel 1: Type S Error\n# ----------------------------------------\np1 <- ggplot(df, aes(x = TrueEffect, y = TypeS)) +\n  geom_line(color = \"darkred\", size = 1.5) +\n  geom_vline(xintercept = assumed_effect, linetype = \"dashed\", color = \"green\", linewidth = 1) +\n  geom_vline(xintercept = observed_effect, linetype = \"dotted\", color = \"black\", linewidth = 1) +\n  annotate(\"text\", x = .1, y = 0.42,\n           label = paste(\"Assumed +0.20\\nPower =\", round(power_assumed, 2)),\n           color = \"green\", hjust = -0.1, size = 5) +\n  annotate(\"text\", x = observed_effect, y = 0.42,\n           label = paste(\"Observed =\", observed_effect,\n                         \"\\nPower =\", round(power_observed, 2),\n                         \"\\nType S =\", round(type_s_observed, 2)),\n           color = \"black\", hjust = 1.1, size = 5) +\n  labs(title = \"Type S Error vs True Effect Size\",\n       subtitle = paste(\"Observed =\", observed_effect, \"| SE =\", round(se, 4)),\n       x = \"True Effect Size (Caf - Decaf)\",\n       y = \"Type S Error Probability\") +\n  custom_theme\n\n# ----------------------------------------\n# Panel 2: Exaggeration Ratio\n# ----------------------------------------\np2 <- ggplot(df, aes(x = TrueEffect, y = Exaggeration)) +\n  geom_line(color = \"steelblue\", size = 1.5) +\n  geom_vline(xintercept = assumed_effect, linetype = \"dashed\", color = \"green\", size = 1) +\n  geom_vline(xintercept = observed_effect, linetype = \"dotted\", color = \"black\", size = 1) +\n  annotate(\"text\", x = .1, y = max(df$Exaggeration)*0.85,\n           label = paste(\"Assumed +0.20\\nPower =\", round(power_assumed, 2)),\n           color = \"green\", hjust = -0.1, size = 5) +\n  annotate(\"text\", x = 0, y = 30,\n           label = paste(\"Observed =\", observed_effect,\n                         \"\\nPower =\", round(power_observed, 2),\n                         \"\\nType M =\", round(type_m_observed, 2)),\n           color = \"black\", hjust = 1.1, size = 5) +\n  xlim(-0.10, 0.10) +\n  ylim(0,50) +\n  labs(title = \"Exaggeration Ratio vs \\nTrue Effect Size\",\n       x = \"True Effect Size (Caf - Decaf)\",\n       y = \"Exaggeration Ratio\") +\n  custom_theme\n\n# ----------------------------------------\n# Panel 3: Power\n# ----------------------------------------\np3 <- ggplot(df, aes(x = TrueEffect, y = Power)) +\n  geom_line(color = \"darkgreen\", size = 1.5) +\n  geom_vline(xintercept = assumed_effect, linetype = \"dashed\", color = \"green\", size = 1) +\n  geom_vline(xintercept = observed_effect, linetype = \"dotted\", color = \"black\", size = 1) +\n  annotate(\"text\", x = .05, y = 0.8,\n           label = paste(\"Assumed +0.20\\nPower =\", round(power_assumed, 2)),\n           color = \"green\", hjust = -0.1, size = 5) +\n  annotate(\"text\", x = 0, y = 0.8,\n           label = paste(\"Observed =\", observed_effect,\n                         \"\\nPower =\", round(power_observed, 2)),\n           color = \"black\", hjust = 1.1, size = 5) +\n  labs(title = \"Power vs \\nTrue Effect Size\",\n       x = \"True Effect Size (Caf - Decaf)\",\n       y = \"Power\") +\n  custom_theme\n\n# ----------------------------------------\n# Save combined plots\n# ----------------------------------------\n\ncombined_plot <- p1 / p2 / p3\ncombined_plotMP <- p3 + p2\nggsave(\"output/decaf_retrodesign_panels_polished.png\", combined_plot, width = 10, height = 14, dpi = 300)\n\ncombined_plotMP\n```\n:::\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Histogram of 20,000 simulations drawn from Binomical (200, 0.5)](output/decaf_retrodesign_panels_polished.png){fig-align='center' width=600px}\n:::\n:::\n\n\n3. A lack of specification as to which arm (abstinence or caffeinated) is hypothesized to have the reduced risk. This ambiguity creates interpretive flexibility as whichever arm shows benefit could be claimed as success.  Such directional absence hinders inference and inflates the risk of misleading conclusions.  This lack of statistical clarity is evident not only in the published article but also in the [trial protocol](https://cdn.jamanetwork.com/ama/content_public/journal/jama/0/joi250099supp1_prod_1762458119.41086.pdf?Expires=1766002960&Signature=veUO2luJ-u-d2v~RtBHqQYJC2JetjhjFXQ2J-Eyc49InJ9BYIPTzVjFxE7oZF7BTlAN7g8~HXiemM2Oh5AbgAaVaInX2CpjN0TujOBrJmE5uc4HCUffwRztEF3x-I7X3m5j8a2cvoGbjfqEIHXGVgY95WpCLsV4H~3Xbiorj-Q1imZOtOl3~q9qwYSifSymwWG1CyjaGrBo8RF8zpCVo7pdZY1eTv2kh9Q-9I5ysrMIgnlLCmT5OcOYdVYt2i1nkzqOpMg9m7DU62l68iAOeP5r-7-towaGgMkpsGHv1qAID4JMgcv4J1ql~DJQlpkMKvALXpRUBbdUAZs6DXRn~9A__&Key-Pair-Id=APKAIE5G5CRDK6RD3PGA) and  trial registration documentation at [ClinicalTrials.gov](https://clinicaltrials.gov/study/NCT05121519#study-plan). It is disconcerting that these design issues were overlooked not only by the authors but also apparently by peer reviewers, journal editors, and national funding agencies. These design flaws contribute to uncertainty in interpreting the final results.\n\n## DECAF Trial Results\n\nIn the caffeinated coffee group, 47% of patients  had an AF or atrial flutter recurrence compared to 64% recurrence in the decaf group (hazard ratio, 0.61 [95%CI, 0.42-0.89],). The authors concluded \n\n> \"...allocation to consumption of caffeinated coffee averaging 1 cup a day was\n[**associated**]{.red-text} with less recurrence of AF or atrial flutter compared with abstinence from coffee and caffeinated products.\"[@RN1]\n\nGiven the randomized design and the statistically significant result (p = 0.01), it is surprising that the conclusion wasn't \n\n> > ...allocation to consumption of caffeinated coffee averaging 1 cup a day \n[**caused**]{.red-text} less recurrence of AF or atrial flutter compared with abstinence from coffee and caffeinated products.\n\nThe results were summarized in the Figure below.    \n\n![Cumulative incidence curve from DECAF trial[@RN1] showing higher recurrence rates in the decaf group (blue) versus caffeinated group (orange).](input/decaf_CI_plot.png){fig-align=\"center\" fig-height=\"400\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Observed data\n\na_success <- 64  # decaf group\na_total <- 100\nb_success <- 47  # caffeinated group\nb_total <- 100\n\n# Proportions\np1 <- a_success / a_total\np2 <- b_success / b_total\n\n# Risk Difference\nrd <- p1 - p2\n\n# Standard error for RD\nse_rd <- sqrt((p1 * (1 - p1) / a_total) + (p2 * (1 - p2) / b_total))\n\n# 95% CI\nz <- 1.96\nci_low <- rd - z * se_rd\nci_high <- rd + z * se_rd\np <- 2 * (1 - pnorm(abs(rd / se_rd)))\n\n# Print results\n# cat(\"Risk Difference (RD):\", round(rd * 100, 2), \"%\\n\")\n# cat(\"95% CI:\", round(ci_low * 100, 2), \"% to\", round(ci_high * 100, 2), \"%\\n\")\n```\n:::\n\n\n\n## Bayesian reanalysis of DECAF (survival modeling)\n\nThe small p-value (p(data|null hypothesis) informs us that observing this data or more extreme data, if there was no true effect is unlikely. The inverse probability (p(effect|data) is arguably of greater interest and provides additional insights, most importantly the ability to include prior knowledge and to provide probability estimates of benefit or harm. Inverse probability, or Bayesian analyses, of survival data requires individual patient data (IPD) and well justified priors, which summarize the state of knowledge before seeing the data. Priors are often deemed the Achilles' heel of Bayesian analyses, but well justified, transparent and robust testing of different priors can mitigate subjectiveness concerns. In Bayesian reanalyses of completed studies, prior beliefs can sometimes be extracted from the original power calculations. For example, the DECAF[@RN1] authors assumed a baseline recurrence risk of 50% with a 41% relative risk reduction and therefore a 29.5% risk in the intervention group (0.50 - 0.50*0.41 = 0.295). However we are now faced with the previous identification problem of the direction in the projected improvement. Did DECAF[@RN1] authors believe that the risk reduction would be with decaffeinated or caffeinated exposure? Given the prevailing belief of caffeine as a proarrhythmic agent and given that the study population was comprised initially of coffee drinkers, with the intervention being abstinence we assume the proposed relative risk reduction is in favor of the decaffeinated group.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nagg2 <- data.frame(\n  group = factor(c(\"caffeinated\", \"abstinence\"),\n                 levels = c(\"abstinence\", \"caffeinated\")),  # reference first\n  y     = c(47, 64),\n  n     = c(100, 100)\n)\nstopifnot(all(levels(agg2$group) == c(\"abstinence\",\"caffeinated\")))\n\n# Observed counts by group (named vector) — used later to align PPCs\ny_obs_by_group <- with(agg2, setNames(y, as.character(group)))\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# ------------------------------------------------------------\n# PRIOR CONSTRUCTION BASED ON DECAF PUBLICATION\n# Since with use binomial model with logit link, we need to convert\n# the RR-based prior into log-OR scale for class=\"b\" and \n# logit scale for class=\"Intercept\"\n# ------------------------------------------------------------\n# 1: Decaf (reference) reduces risk by 41% vs caffeinated.\nRR_decaf_vs_caff <- 0.59  # 1- RRR = 1 - 0.41 = 0.59\n\n# 2: Baseline risk you want to anchor is caffeinated = 0.50.\np_caff_baseline  <- 0.50\n\n# Function to convert probabilities to odds ratio to logOR \n# Given RR(decaf vs caff) and p_caff, compute p_decaf, OR(caff vs decaf), \n# logOR(caff vs decaf), and Intercept mean = logit(p_decaf).\nfrom_RR_and_p_caff <- function(RR_decaf_vs_caff, p_caff) {\n  stopifnot(RR_decaf_vs_caff > 0, p_caff > 0, p_caff < 1)\n  p_decaf <- RR_decaf_vs_caff * p_caff  # decaf risk = RR * caffeinated risk\n  if (p_decaf <= 0 || p_decaf >= 1) {\n    warning(sprintf(\"Implied p_decaf = %.3f outside (0,1). Adjust RR or p_caff.\", p_decaf))\n  }\n  odds_caff  <- p_caff  / (1 - p_caff)\n  odds_decaf <- p_decaf / (1 - p_decaf)\n  OR_caff_vs_decaf   <- odds_caff / odds_decaf\n  logOR_caff_vs_decaf<- log(OR_caff_vs_decaf)\n  mu_intercept       <- qlogis(p_decaf)       # baseline (decaf) on logit scale\n  list(\n    p_caff       = p_caff,\n    p_decaf      = p_decaf,\n    OR           = OR_caff_vs_decaf,\n    logOR        = logOR_caff_vs_decaf,  # prior mean for class=\"b\"\n    mu_intercept = mu_intercept          # prior mean for class=\"Intercept\"\n  )\n}\n\nconv <- from_RR_and_p_caff(RR_decaf_vs_caff, p_caff_baseline)\nmu_b <- conv$logOR  # prior mean for b_groupcaffeinated (log-OR: caff vs decaf) ≈ +0.871\nmu_intercept <- conv$mu_intercept # prior mean for Intercept = logit(p_decaf) ≈ -0.871\np_decaf_prior_center <- plogis(mu_intercept)\n\n# message(sprintf(\"Prior centers: logOR_b ≈ %.3f (OR ≈ %.2f), Intercept ≈ %.3f => p_decaf ≈ %.3f\",  mu_b, exp(mu_b), mu_intercept, p_decaf_prior_center))\n\n# Prior SDs: tune to reflect how strongly you want to encode the belief.\nsd_b <- 0.5          # narrower = stronger prior on treatment effect\nsd_intercept <- 1.5  # weakly-informative baseline for decaf\n\npriors <- c(\n  set_prior(sprintf(\"normal(%g, %g)\", mu_b,         sd_b),         class = \"b\"),\n  set_prior(sprintf(\"normal(%g, %g)\", mu_intercept, sd_intercept), class = \"Intercept\")\n)\n\n# alternative prior\n#priors <- c(set_prior(paste0(\"normal(\", mu_b, \", \", sd_b, \")\"),\n#            class = \"b\", coef = \"groupcaffeinated\"),\n# set_prior(paste0(\"normal(\", mu_intercept, \", \", sd_intercept, \")\"), class =  \"Intercept\"))\n```\n:::\n\n\nThe priors for both treatment effect and baseline risk can be specified as normal distributions on the log-odds scale. Based on the assumptions used by the DECAF investigators, the distributional parameters for the baseline control prior will be mean centered at their belief of a 50% recurrence risk (0 on the logit scale) with a standard deviation of 1.5, indicating a weakly informative prior. Similarly, the prior for the treatment effect will be centered at 29.5% (-0.871 on the logit scale) with an assumed standard deviation of 0.5, reflecting slightly higher confidence in our ability to estimate effect size variability. The reasonableness of these priors can be assessed through prior predictive checks which demonstrates that these priors adequately reflect the DECAF position of considerable uncertainty with a wide range of possible effect sizes, principally with expected benefit (93.5% probability), but a small probability of harm, for the intervention versus control.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(scales)\n\n# ======================================================\n# Prior predictive for a two-arm Binomial trial\n# and effect-measure plots with requested axis settings\n# ======================================================\n\n\n# -----------------------------\n# 1) Prior specification (EDIT)\n# -----------------------------\n# Baseline (control) log-odds prior: theta0 ~ Normal(mu0, sd0^2)\nmu0 <- 0.0       # logit(0.50) = 0\nsd0 <- 1.5       # weakly-informative baseline prior\n\n# Treatment effect prior on log-odds ratio: delta ~ Normal(mud, sdd^2)\nmud <- -0.871    # ≈ logit(0.295) - logit(0.50), belief of ~29.5% at 50% baseline\nsdd <- 0.5       # moderately informative\n\n# Planned sample sizes (EDIT as needed)\nnC <- 150\nnT <- 150\n\n# Number of prior draws (increase for smoother densities)\nS <- 100000\nset.seed(1)\n\n# -----------------------------\n# 2) Simulate from the priors\n# -----------------------------\nlogistic <- function(x) 1 / (1 + exp(-x))\n\ntheta0 <- rnorm(S, mean = mu0, sd = sd0)   # baseline log-odds\ndelta  <- rnorm(S, mean = mud, sd = sdd)   # treatment log-OR\n\npC <- logistic(theta0)          # true control probability\npT <- logistic(theta0 + delta)  # true treatment probability\n\n# -----------------------------\n# 3) Prior predictive data\n# -----------------------------\nYC <- rbinom(S, size = nC, prob = pC)\nYT <- rbinom(S, size = nT, prob = pT)\n\nhat_pC <- YC / nC\nhat_pT <- YT / nT\n\n# -----------------------------\n# 4) Effect measures\n# -----------------------------\n# Risk difference: RD = p_hat_T - p_hat_C (benefit shows as negative)\nRD <- hat_pT - hat_pC\n\n# Risk ratio\neps <- 1e-12\nRR <- (hat_pT + eps) / (hat_pC + eps)\n\n# Odds ratio\nOR <- ((hat_pT + eps) / (1 - hat_pT + eps)) /\n  ((hat_pC + eps) / (1 - hat_pC + eps))\n\nlogRR <- log(RR)\nlogOR <- log(OR)\n\n# ---------------------------\n# log(OR): x in [-3, +1]\n# ---------------------------\np_logOR <- ggplot(data.frame(x = logOR), aes(x = x)) +\n  geom_density(fill = \"#9ECAE1\", color = \"#3182BD\", alpha = 0.3, adjust = 1.0) +\n  geom_vline(xintercept = 0, linetype = \"dashed\", color = \"grey40\") +\n  coord_cartesian(xlim = c(-3, 1)) +\n  labs(\n    title = \"Prior Predictive: log Odds ratio\",\n    x = \"log(OR)\", y = \"Density\"\n  ) +\n  theme_minimal(base_size = 12)\n\n\n\n# ---------------------------\n# log(RR): x in [-3, +1]\n# ---------------------------\np_logRR <- ggplot(data.frame(x = logRR), aes(x = x)) +\n  geom_density(fill = \"#CFE8B9\", color = \"#31A354\", alpha = 0.3, adjust = 1.0) +\n  geom_vline(xintercept = 0, linetype = \"dashed\", color = \"grey40\") +\n  coord_cartesian(xlim = c(-3, 1)) +\n  labs(\n    title = \"Prior Predictive: log Risk ratio\",\n    x = \"log(RR)\", y = \"Density\"\n  ) +\n  theme_minimal(base_size = 12)\n\npr_RD_gt0 <- mean(logRR > 0)\nggsave(\"output/prior_predictive_logRR.png\", width = 6, height = 4, dpi = 300)\n\n# ---------------------------\n# Risk difference (p̂T − p̂C), scaled per 100 patients\n# ---------------------------\n\nRD100 <- 100 * RD  # keep sign: benefit-negative if pT < pC\n\n# Tail probability for \"worse than control\" (RD > 0)\npr_RD_gt0 <- mean(RD > 0)\n\n# Density for shading region RD > 0 (i.e., > 0 per 100 after scaling too)\nden_RD <- density(RD100, adjust = 1.0, na.rm = TRUE)\ndf_RD  <- data.frame(x = den_RD$x, y = den_RD$y)\n\n# Reasonable x-limits from central mass; edit if you prefer fixed limits\nxlim_rd <- quantile(RD100, c(0.005, 0.995), na.rm = TRUE)\n\np_RD100 <- ggplot(df_RD, aes(x = x, y = y)) +\n  # Shade the >0 side (treatment worse under RD = pT - pC)\n  geom_area(data = subset(df_RD, x > 0), fill = \"#FDAE6B\", alpha = 0.35) +\n  # Outline full density\n  geom_line(color = \"#E6550D\", linewidth = 1.0) +\n  geom_vline(xintercept = 0, linetype = \"dashed\", color = \"grey40\") +\n  coord_cartesian(xlim = xlim_rd) +\n  labs(\n    title = \"Prior Predictive: Absolute risk difference\",\n    subtitle = sprintf(\"Shaded area: P(RD > 0) = %.3f\", pr_RD_gt0),\n    x = \"Absolute risk difference (per 100 patients)\",  # still p̂T − p̂C\n    y = \"Density\"\n  ) +\n  theme_minimal(base_size = 12)\n\nggsave(\"output/prior_predictive_RD100.png\", width = 6, height = 4, dpi = 300)\n```\n:::\n\n   \nIn addition to the priors, the Bayesian survival analysis requires the individual patient data (IPD). Cumulative incidence data available in graphical format (DECAF[@RN1] Figure3), were extracted with WebPlotDigitizer[@RN7716] and transformed into survival format to generate a Kaplan–Meier (KM) plot using the Guyot et al[@RN5762] algorithm that incorporates numbers at risk and event counts. This method was implemented via the IPDfromK `R` package[@IPDfromKM] providing a robust and validated approach for reconstructing IPD from published survival curves for secondary analyses. The success in extracting the IPD is evident in the complete overlap between the reconstructed KM curves and the original published curves (see Figure below).\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# ================== 1) Read & tidy your CSV ==================\n\ndf <- read_csv(\"input/decaf_incident_data.csv\",\n               col_names = c(\"coffee_time\",\"coffee_inc\",\"decaf_time\",\"decaf_inc\"),\n               skip = 2, show_col_types = FALSE)\n\ncoffee_xy <- df %>% filter(!is.na(coffee_time) & !is.na(coffee_inc)) %>%\n  transmute(time = coffee_time, inc = coffee_inc) %>%\n  arrange(time) %>% distinct(time, .keep_all = TRUE)\n\ndecaf_xy  <- df %>% filter(!is.na(decaf_time)  & !is.na(decaf_inc)) %>%\n  transmute(time = decaf_time,  inc = decaf_inc)  %>%\n  arrange(time) %>% distinct(time, .keep_all = TRUE)\n\n# Truncate raw digitized series at 180 days \ncoffee_xy <- coffee_xy %>% filter(time <= 180)\ndecaf_xy  <- decaf_xy  %>% filter(time <= 180)\n\n# ================== 2) Incidence(%) -> Survival(%) for reconstruction ==================\ncoffee_km <- coffee_xy %>% transmute(time, surv = pmax(0, 100 - inc))\ndecaf_km  <- decaf_xy  %>% transmute(time, surv = pmax(0, 100 - inc))\nif (min(coffee_km$time) > 0) coffee_km <- bind_rows(tibble(time = 0, surv = 100), coffee_km)\nif (min(decaf_km$time)  > 0) decaf_km  <- bind_rows(tibble(time = 0, surv = 100),  decaf_km)\n\n# ================== 3) At-risk tables (yours) ==================\ntrisk <- c(0, 30, 60, 90, 120, 150, 180)\nnrisk_coffee <- c(100, 79, 70, 61, 57, 56, 52)\nnrisk_decaf  <- c(100, 64, 53, 47, 45, 38, 36)\n\n# ================== 4) Reconstruct IPD (Guyot method via IPDfromKM) ==================\n\nprep_coffee <- preprocess(as.matrix(coffee_km), trisk = trisk, nrisk = nrisk_coffee, maxy = 100)\nprep_decaf  <- preprocess(as.matrix(decaf_km),  trisk = trisk, nrisk = nrisk_decaf,  maxy = 100)\n\nipd_coffee <- getIPD(prep_coffee, armID = 1)$IPD  # coffee arm\nipd_decaf  <- getIPD(prep_decaf,  armID = 0)$IPD  # decaf arm\n\nipd <- bind_rows(\n  data.frame(time = ipd_coffee$time, status = ipd_coffee$status, arm_coffee = 1L),\n  data.frame(time = ipd_decaf$time,  status = ipd_decaf$status,  arm_coffee = 0L)\n)\n\n# ================== 5) Truncate ANALYSIS at 180 days ==================\nipd <- ipd %>%\n  mutate(time_orig = time, status_orig = status,\n         time = pmin(time, 180),\n         status = ifelse(time_orig > 180, 0L, status_orig)) %>%\n  select(-time_orig, -status_orig)\n\n# ================== 6) Frequentist Cox (authors’ coding: coffee=1, decaf=0) ==================\nfit_cox <- coxph(Surv(time, status) ~ arm_coffee, data = ipd)\ns_cox   <- summary(fit_cox)\nhr      <- exp(coef(fit_cox)[\"arm_coffee\"])\nci_95   <- exp(confint(fit_cox)[\"arm_coffee\", ])\np_value <- s_cox$coefficients[\"arm_coffee\", \"Pr(>|z|)\"]\n# cat(sprintf(\"\\nFrequentist Cox (coffee vs decaf): HR = %.2f (95%% CI %.2f–%.2f); p = %.3f\\n\", hr, ci_95[1], ci_95[2], p_value))\n\n# ================== 7) KM plot (truncated at 180 days) ==================\nkm_fit <- survfit(Surv(time, status) ~ arm_coffee, data = ipd)\np_km <- ggsurvplot(\n  km_fit, data = ipd, conf.int = FALSE, risk.table = TRUE,\n  xlim = c(0, 180),\n  legend.labs = c(\"Decaf (control)\", \"Coffee (intervention)\"),\n  legend.title = \"\", palette = c(\"#D95F02\",\"#1B9E77\")\n)\n\nggsave(\"output/km_plot_coffee_vs_decaf.png\", p_km$plot, width = 7, height = 5, dpi = 300)\n\n# ================== 8) Cumulative incidence overlay: digitized vs reconstructed ==================\n# Reconstructed cumulative incidence from KM (in %)\nkm_df <- survminer::surv_summary(km_fit) %>%\n  mutate(cuminc = 100 * (1 - surv),\n         arm = ifelse(strata == \"arm_coffee=0\", \"Decaf (KM)\", \"Coffee (KM)\")) %>%\n  select(time, cuminc, arm)\n\n# Digitized cumulative incidence (already in %), labeled\ndig_df <- bind_rows(\n  coffee_xy %>% transmute(time, cuminc = inc, arm = \"Coffee (digitized)\"),\n  decaf_xy  %>% transmute(time, cuminc = inc, arm = \"Decaf (digitized)\")\n)\n\np_ci <- ggplot() +\n  geom_step(data = km_df, aes(x = time, y = cuminc, color = arm), linewidth = 1) +\n  geom_line(data = dig_df, aes(x = time, y = cuminc, color = arm), linetype = \"dashed\") +\n  scale_color_manual(values = c(\"Coffee (KM)\"=\"#1B9E77\",\"Decaf (KM)\"=\"#D95F02\",\n                                \"Coffee (digitized)\"=\"#1B9E77\",\"Decaf (digitized)\"=\"#D95F02\")) +\n  coord_cartesian(xlim = c(0,180), ylim = c(0,100)) +\n  labs(title = \"Cumulative incidence (reconstructed KM vs digitized points)\",\n       x = \"Days\", y = \"Cumulative incidence (%)\",\n       color = NULL) +\n  scale_x_continuous(breaks = c(30, 60, 90, 120, 150, 180)) +\n  scale_y_continuous(breaks = c(20, 40, 60, 80, 100)) +\n  theme_minimal(base_size = 12) +\n  theme(legend.position = \"bottom\")\n\nggsave(\"output/cumulative_incidence_overlay.png\", p_ci, width = 7, height = 5, dpi = 300)\n```\n:::\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Cumulative incidence (reconstructed KM vs digitized points) showing almost perfect concordance](output/cumulative_incidence_overlay.png){fig-align='center' width=600px}\n:::\n:::\n\n\nThe IPD calculated frequentist survival analysis results, HR = 0.62 (95% CI 0.43–0.91), p = 0.014, closely matches the published DECAF[@RN1] results, confirming the accuracy of the IPD reconstruction process.\n\nOnce the priors and IPD are specified, we can proceed with the Bayesian survival regression modelling. As Cox regression uses the partial likelihood, which cancels out the baseline hazard when estimating the regression coefficients (i.e., log‑HRs), in a Bayesian Cox survival model we only need a prior for the the treatment effect.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#| label: compile-brms\n#| message: true\n#| warning: true\n#| error: true\n\n# ================== 9) Bayesian Cox in brms (coffee vs decaf) ==================\n# Prior: belief that decaf is better -> coffee harmful a priori.\n# Encode as Normal(+0.871, 0.5) on the coffee coefficient (log-HR).\nipd_brm <- ipd %>% mutate(cens = 1L - status)  # brms uses 1=censored\n\nprior_cox <- c(\n  set_prior(\"normal(0.871, 0.5)\", class = \"b\", coef = \"arm_coffee\")\n)\n\n\n#| message: false\n#| warning: false\n\nfit_brm_cox <- quiet_brms(\n  time | cens(cens) ~ arm_coffee,\n  data    = ipd_brm,\n  family  = cox(),\n  prior   = prior_cox,\n  backend = \"cmdstanr\",\n  chains  = 4, iter = 2500, warmup = 1000, seed = 20251114,\n  refresh = 0, control = list(adapt_delta = 0.999, max_treedepth = 13)\n)\n\n# print(fit_brm_cox)\n\n# ---- Finish: summarize posterior HR and a simple probability statement ----\npost_cox <- posterior_summary(fit_brm_cox, variable = \"b_arm_coffee\")\nHR_post  <- exp(unlist(post_cox[1, c(\"Estimate\",\"Q2.5\",\"Q97.5\")]))\n\n# cat(sprintf(\"\\nBayesian Cox (coffee vs decaf): HR = %.2f (95%% CrI %.2f–%.2f)\\n\", HR_post[1], HR_post[2], HR_post[3]))\n\n# Optional: posterior probability that coffee is beneficial (HR < 1)\ndraws_b <- as_draws_df(fit_brm_cox)[[\"b_arm_coffee\"]]\n# cat(sprintf(\"Pr(HR < 1 | data, prior) = %.3f\\n\", mean(draws_b < 0)))\n```\n:::\n\nThe Bayesian posterior hazard ratio is 0.74 (95% CrI 0.53–1.04), suggesting that caffeinated coffee consumption may be associated with a lower risk of AF recurrence compared to decaffeinated coffee but the strength of the conclusion has been tempered by the prior belief that decaffeinated and not caffeinated, coffee would be beneficial. Graphically this shift of the observed result by the prior belief is shown in the Figure below. Notice also the width of the posterior probability has narrowed, underscoring that our new data has decreased our uncertainty about the effect of coffee.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(posterior)\n\n# ---- 1) Extract posterior draws of the treatment coefficient from brms Cox ----\n# Your model formula was: time | cens(cens) ~ arm_coffee\ndraws_df <- as_draws_df(fit_brm_cox)\n\n# Robustly locate the coefficient in case the name changes; print names if needed\n# print(names(draws_df)[grepl(\"^b_\", names(draws_df))])\n\nstopifnot(\"b_arm_coffee\" %in% names(draws_df))\npost_b <- draws_df[[\"b_arm_coffee\"]]   # log-HR for caffeinated (1) vs decaf (0)\n\n# ---- 2) Generate prior draws with same length (coffee harmful a priori) ----\nS <- length(post_b)\nprior_mu <- +0.871   # your belief: decaf better -> coffee harmful on log-(hazard) scale\nprior_sd <- 0.5\nprior_b  <- rnorm(S, mean = prior_mu, sd = prior_sd)\n\n# ---- 3) Combine to long format ----\ndf_b <- bind_rows(\n  data.frame(value = prior_b, which = \"Prior\"),\n  data.frame(value = post_b,  which = \"Posterior\")\n)\n\n# ---- 4) Observed value and posterior mean (for vertical lines) ----\nx_obs       <- log(0.61)                    # authors' frequentist estimate\npost_mean   <- mean(post_b, na.rm = TRUE)   # posterior mean of log-HR\npost_meanHR <- exp(post_mean)\n\n# ---- 5) Plot: Prior vs Posterior on log-HR with reference lines ----\np <- ggplot(df_b, aes(x = value, colour = which, fill = which)) +\n  geom_density(alpha = 0.15, linewidth = 0.9) +\n  geom_vline(xintercept = x_obs, colour = \"grey30\", linetype = \"dashed\", linewidth = 0.8) +\n  geom_vline(xintercept = post_mean, colour = \"#E34A33\", linetype = \"dotdash\", linewidth = 0.9) +\n  labs(\n    color = NULL, fill = NULL, x = \"log-HR (caffeinated vs decaf)\",\n    y = NULL,\n    title = \"Prior vs Posterior for log-HR (caffeinated vs decaf)\",\n    subtitle = sprintf(\"Observed HR = 0.61 (log = %.3f). Posterior mean HR ≈ %.2f (log = %.3f).\",\n                       x_obs, post_meanHR, post_mean),\n    caption = \"DECAF prior +0.871  indicating \\n decaffienated risk < coded caffeinated .\"\n  ) +\n  theme_bw() +\n  theme(plot.caption = element_text(size = 9))\n\nhr_breaks     <- c(0.4, 0.5, 0.61, 0.75, 1, 1.25, 1.5, 2)\nlog_hr_breaks <- log(hr_breaks)\n\np <- p + scale_x_continuous(\n      name = \"log-HR (caffeinated vs decaf)\",\n      sec.axis = sec_axis(~ ., breaks = log_hr_breaks, labels = hr_breaks,\n                          name = \"Hazard ratio (caffeinated vs decaf)\")\n    )\nggsave(\"output/prior_vs_posterior_logHR.png\", p, width = 7, height = 5, dpi = 300)\n\n\n# ---- 6) Probability coffee has clinically meaningful benefit (HR < 0.9) ----\n\n\np_hr_lt_0_9 <- df_b %>%\n  filter(which == \"Posterior\") %>%\n  summarise(prob = mean(value < log(0.9), na.rm = TRUE)) %>%\n  pull(prob)\n\n# sprintf(\"%.3f\", p_hr_lt_0_9)\n# round(p_hr_lt_0_9, 3)\n```\n:::\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Prior vs Posterior for log-HR (caffeinated vs decaf)](output/prior_vs_posterior_logHR.png){fig-align='center' width=600px}\n:::\n:::\n\n\nDespite this shift, the posterior probability remains high that caffeinated coffee has a beneficial effect (HR < 1) is 96%. However, the probability that caffeinated coffee has a clinically meaningful benefit, for example a HR < 0.9, falls to 88%. Increasing the threshold of what represents a clinically meaningful decrease, will lead to a corresponding reduction in the probability of a beneficial caffeine effect. \n\n\n## Bayesian reanalysis of DECAF (risk difference)\n\n \n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(brms)\nlibrary(ggplot2)\nlibrary(ggtext)   # <- for colored text in subtitle\n\n# ---- Priors ----\nmu0 <- 0.0      # baseline log-odds\nsd0 <- 1.5\nmud <- -0.871   # mean of prior for log-OR (caffeinated vs decaf) on logit scale\nsdd <- 0.5\nset.seed(1234)\n\n# ---- Fit Bayesian binomial model ----\n# The model will be run with 4 chains, each with 4000 iterations (1000 warmup), and using the `cmdstanr` backend for efficient sampling. The `adapt_delta` control parameter is set to 0.95 to help ensure convergence. \n\nfit_binom2 <- quiet_brms(\n  formula = y | trials(n) ~ group, # groupcaffeinated is log-OR(caff vs decaf)\n  data = agg2,\n  family = binomial(link = \"logit\"),\n  prior = priors,\n  chains = 4,\n  iter = 4000,\n  warmup = 1000,\n  refresh = 0,\n  backend = \"cmdstanr\",\n  control = list(adapt_delta = 0.95)\n)\n# print(summary(fit_binom2), digits = 3)\n\n\n# ---- Posterior RD (caffeinated − decaffeinated) ----\nnd <- data.frame(group = c(\"abstinence\", \"caffeinated\"), n = c(100, 100))\neta_post <- posterior_linpred(fit_binom2, newdata = nd, transform = FALSE)\np_post   <- plogis(eta_post)\nrd_post  <- p_post[, 2] - p_post[, 1]  # caffeinated − decaffeinated\n\npost_mean <- mean(rd_post)\npost_sd <- sd(rd_post)\npost_ci   <- quantile(rd_post, c(0.025, 0.975))\n# pnorm((0 - post_mean) / post_sd)  # Pr(RD < 0 | data, prior) AKA pnorm(0, post_mean, post_sd) \n# clinically significant threshold at RD = -0.02\n# pnorm((-0.02 - post_mean) / post_sd)  # Pr(R\n\n# ---- Observed RD (same direction: caffeinated − decaffeinated) ----\nobs <- aggregate(cbind(y, n) ~ group, data = fit_binom2$data, sum)\nobs <- obs[match(c(\"abstinence\", \"caffeinated\"), obs$group), ]\nobs_rd <- obs$y[2] / obs$n[2] - obs$y[1] / obs$n[1]\n\n# ---- Prior RD (centered > 0 for this RD definition) ----\ntheta0  <- rnorm(length(rd_post), mu0, sd0)   # baseline (decaf) log-odds\ndelta   <- rnorm(length(rd_post), mud, sdd)   # log-OR (caffeinated vs decaf)\np_decaf <- plogis(theta0)\np_caff  <- plogis(theta0 + delta)\n\n# Mirror so prior centers > 0 for RD = caffeinated − decaffeinated\nrd_prior <- -(p_caff - p_decaf)\n# quantile(rd_prior, c(.025,.5,.975))\n\n# ---- Plot ----\ndf <- rbind(\n  data.frame(RD = rd_prior, which = \"Prior\"),\n  data.frame(RD = rd_post,  which = \"Posterior\")\n)\n```\n:::\n\n\nThe DECAF[@RN1] result can also be expressed as a risk difference, -17% [95% CI; -.03, -.31, p = 0.01]. Again a Bayesian risk difference analysis may facilitate clinical interpretations. The Bayesian model will be fit to the aggregated data of events and total patients in each group. The model formula specifies a binomial likelihood with a logit link function, appropriate for binary outcome data. The previously developped priors based on the DECAF power calculation can be transformed to the risk difference scale. The Bayesian posterior risk difference, based on these prior beliefs and the observed data is 7.6% (95% CrI: -19.5% to 4.4%), in favor of the caffeinated group. This posterior risk difference showed a shift towards the null compared to the frequentist result, due to the prior's influence even thought it was left purposely vague due to reflect the lack of previous consensus concerning the intervention's value in this population (see Figure below). The prior favored a posterior probability, 89.3%, for decaffeinated benefit but did allocate a smaller probability (10.7%) for a possible caffeinated benefit. While the final result suggests a caffeinated coffee benefit, the strength of the evidence in favor of this benefit is seen as modest at best, and certainly much less than implied by the original analysis. For example, the probability of a clinically meaningful benefit (e.g., say arbitrarily RD < -0.02 or number needed to treat = 50) drops to 82%.  \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(df, aes(x = RD*100, fill = which, color = which)) +\n  geom_density(alpha = 0.18, adjust = 1) +\n  geom_vline(xintercept = 0,        linetype = \"dashed\", color = \"black\") +\n  geom_vline(xintercept = obs_rd*100,   linetype = \"dashed\", color = \"green3\") +\n  geom_vline(xintercept = post_mean*100,linetype = \"dashed\", color = \"firebrick\") +\n  # Remove legend title by naming the scales NULL\n  scale_fill_manual(name = NULL, values = c(Prior = \"#00BCD4\", Posterior = \"#F08080\")) +\n  scale_color_manual(name = NULL, values = c(Prior = \"#00BCD4\", Posterior = \"#F08080\")) +\n  labs(\n    title = \"Prior vs Posterior for risk difference (RD)\",\n    # Color words in subtitle using <span style='color:...'> and ggtext\n    subtitle = sprintf(\n      \"Observed RD (<span style='color:green3;'>green line</span>) = %.1f%%, Posterior mean RD (<span style='color:firebrick;'>red line</span>) = %.1f%%\",\n      100 * obs_rd, 100 * post_mean\n    ),\n    caption = \"DECAF assumed prior decaffienated < caffeinated risk \\nmirrored > 0 since RD axis is (caffeinated - decaf)\",\n    x = \"Risk difference (caffeinated − decaffeinated) / 100 treated\",\n    y = \"Density\"\n  ) +\n  xlim(c(-30, 50)) +\n  theme_minimal(base_size = 13) +\n  theme(\n    # Enable HTML rendering for the subtitle\n    plot.subtitle = ggtext::element_markdown()\n  )\nggsave(\"output/prior_vs_posterior_RD.png\", width = 7, height = 5, dpi = 300)\n```\n:::\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Prior vs Posterior for risk difference (RD)](output/prior_vs_posterior_RD.png){fig-align='center' width=600px}\n:::\n:::\n\n\n## Discussion\n\nDECAF[@RN1] was a well performed clinical trial with successful randomization and no lost to follow-up. The trial was unblinded but events were adjudicated by treating physicians and not study coordinators so this risk of bias appears low. No other obvious biases were identified yet the results were highly \"unexpected\" or \"surprising\". The published analysis apparently provides a definitive answer in favor of the caffeinated group (p = .01). Notwithstanding DECAF's[@RN1] positive attributes and the emergence of \"dataism\" - the belief that empirical data should guide decisions as characterized by the pithy aphorism “In God we trust. All others have to bring data.”, many clinicians will prefer to trust their intuition or \"gut instinct\" and not encourage coffee consumption or maintence to prevent episodes of recurrent atrial fibrillation. However, reliance on intuition over evidence remains prone to cognitive error[@RN5626].   \n\nGiven the increasing influence of data-driven decision-making, it is essential that statistical interpretations be both rigorous and nuanced, whether frequentist or Bayesian in nature. From a frequentist standpoint, DECAF’s[@RN1] sample size was insufficient to detect realistic effect sizes. Power calculations revealed that the trial had only ~24% power to detect a 15% relative risk reduction, and any statistically significant result from such an underpowered study is likely to exaggerate the true effect — potentially by a factor of two.    \n\nThe Bayesian framework adds further depth by incorporating prior beliefs and quantifies uncertainty in a way that frequentist methods cannot. It enables clinicians to assess not only the most recently observed data but also how to contextualize it by incorporating existing knowledge and beliefs. This is particularly important in scenarios where prior evidence or expert opinion may conflict with new findings.  Using priors derived from the DECAF authors’ own assumptions[@RN1], the Bayesian survival and risk difference models suggest that the strength of evidence favoring caffeinated coffee is more modest than the frequentist interpretation implies. For example, while the posterior probability that caffeinated coffee reduces AF recurrence is high (~96%), the probability of a clinically meaningful benefit (e.g., HR < 0.9) drops to ~88%. On the risk difference scale, the posterior probability of at least absolute  2% reduction in recurrences by avoiding abstinence is 82%. This distinction between statistical and clinical significance is crucial for informed decision-making.    \n\n\nSome may dismiss this reanalysis as statistical alchemy or the “haze of Bayes”[@RN41], but it offers a principled approach to interpreting unexpected findings. In the case of DECAF[@RN1], it tempers over-interpretation by including past beliefs, distinguishes between statistical and clinical significance, and provides the statistical justification for a replication study. This reanalysis can help clinicians make more informed decisions by providing a clearer understanding of the evidence at hand. This is especially important given that over 120 media outlets reported the findings within a week of publication, potentially influencing clinical practice and public behavior based on a single, underpowered study with unexpected, and naively interpreted, results.\n\n## References\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}