[
  {
    "objectID": "posts/2024-02-19-does-it-make-a-difference-sedentary-break/index.html",
    "href": "posts/2024-02-19-does-it-make-a-difference-sedentary-break/index.html",
    "title": "Does it make a difference - sedentary break",
    "section": "",
    "text": "Background\nRecall that the goal of the 605 course is to not only improve critical appraisal skills, but also to think about research questions, designs, and the necessary compromises that are often required in research. Hopefully this adds another dimension to typical journal clubs where either an article in uncritically endorsed enthusiastically or trashed unmercifully, although this is sometimes quite merited This week’s selected article was the 2023 publication Breaking Up Prolonged Sitting to Improve Cardiometabolic Risk: Dose–Response Analysis of a Randomized Crossover Trial concluding\n\nThe present study provides important information concerning efficacious sedentary break doses. Higher-frequency and longer-duration breaks (every 30 min for 5 min) should be considered when targeting glycemic responses, whereas lower doses may be sufficient for BP lowering.\n\nIn this paper, of 25 participants who attended a screening visit, 18 were randomized and 11 completed the randomized crossover designed study which investigated 5 different strategies to examine the acute effects of multiple doses of a light-intensity walking-based sedentary break intervention on cardiometabolic risk factors among middle- and older-age adults. The trial conditions consisted of one uninterrupted sedentary (control) condition and four acute (experimental) conditions that entailed different sedentary break frequency/duration combinations: (1) light-intensity walking every 30 min for 1min, (2) light-intensity walking every 30 min for 5 min, (3) light-intensity walking every 60 min for 1 min, and (4) light-intensity walking every 60 min for 5 min. As the largest response was for glucose differences, will restrict this commentary to that outcome.\nBefore applying any reanalyzing of their data, let’s just stop for a moment and ask ourselves the following question\n\nHow likely do we think a study with only 11 individuals can detect meaningful glucose difference in glucose measurements with these anti sedentary strategies? Would one expect the differences to be so large that they could be detected by this small a sample size?\n\nIn any case, their conclusion appears supported by their published Figure 1 as shown here\n\n\n\n\n\n This Figure is remarkable for 2 main points\n1. The early separation between the control and intervention groups which appears maximum for 5 minutes exercise every 30 minutes\n2. The outcome is not the glucose level from each randomized but the difference in level compared to the control (baseline) group. \nThe early outcome difference\nIn the supplemental material, the authors report summary glucose levels for each group at 15 minute intervals. Using these values, we may simulate the glucose measurements for each group. Let’s consider the values at 45 minutes after T0. Given the authors state that the first 20 minutes are assigned to a standardized meal and that no internvetion occurs before 30 minutes, any variation in the 45 minutes values can’t be due to the intervention. Yet, plotting an analyzing this data (ANOVA) reveals the following\n\n\n[1] \"Analysis of variance using outcome of group glucose - control glucose\"\n\n\n            Df Sum Sq Mean Sq F value   Pr(&gt;F)\ngroup        3   1953     651      10 0.000046\nResiduals   40   2594      65                 \n\n\n\n\n\nFinding these large differences even before any of the interventions could take effect should be a red flag for reservations about the final conclusions.The outcome measure\nUsing the outcome measure as the difference in glucose levels between the active treatments strategies and the control (baseline) group is a potentially fatal flaw. The fatal flaw is using the difference from baseline as their outcome measure. Bland and Altman have published about why this “is biased and invalid, producing conclusions which are, potentially, highly misleading. The actual alpha level of this procedure can be as high as 0.50 for two groups and 0.75 for three”. In short, we need to remember what is being randomized, it is the assignment to a given treatment strategy. Individuals are not randomized to their baseline glucose levels, any more than they are randomized to their weights, heights, eye color, or any other characteristic. With small sample sizes we may well expect that even in randomized samples, there may be meaningful differences in these characteristics, therefore including them as a component of the outcome is not appropriate and may bias the results.Harrell lists all the many assumptions required to be met before analyzing change from baseline could (potentially) be used.\ni. the variable is not used as an inclusion/exclusion criterion for the study, otherwise regression to the mean will be strong\nii. if the variable is used to select patients for the study, a second post-enrollment baseline is measured and this baseline is the one used for all subsequent analysis\niii. the post value must be linearly related to the pre value\niv. the variable must be perfectly transformed so that subtraction “works” and the result is not baseline-dependent\nv. the variable must not have floor and ceiling effects\nvi. the variable must have a smooth distribution\nvii. the slope of the pre value vs. the follow-up measurement must be close to 1.0 when both variables are properly transformed (using the same transformation on both)\nWith this in mind, this study doesn’t meet these assumptions (according to their CONSORT Fig 1, glucose was an entrance criteria, therefore possible regression to the mean may be present, glucose has a definite “floor effect”, and no proof that model is linear).\nTo demonstrate the bias inherent in using change from baseline as opposed to final glucose reading alone, let’s again use the simulated data. We will analyze (ANOVA) and plot the outcome according to treatment where the outcome is i) the final glucose reading in each group or ii) ii) the change from baseline for each group.\n\n\n\n\n\nThis suggests the original analysis is quite wrong and there is likely no difference between the strategies being tested. This is no surprise as with only 11 (or 9) subjects), even with a crossover design, the differences would have to be to very large to reach statistical significance. See the common sense response to the opening question above.\nThere are some other additional discussion points to consider.\n1. While 18 subjects were randomized only 11 were analyzed and 2 of them had missing values. This raises the possibility of a non-quantifiable selection bias.\n2. The authors report a post-hoc power calculation, a statistically inappropriate and nonsensical technique. If a nonsignificant finding was obtained, power will always be low to detect the observed effect size, as observed power is directly related to the obtained P value, with the former providing no additional information than the latter.\n3. There is no discussion of whether these measured outcomes have any clinical relevance. Suppose against all reason, the true glucose incremental area under the curve differential for the best treatment strategy was indeed the reported -11.8 mg% over 8 hours. This translated to 1.4 mg% / hour for an 8 hour day or 0.47 mg% / hour over 24 hours. How likely would this small (i.e. trivial) a difference have any meaningful clinical effect? Important to recall the adage“Measure what is important and don’t make important what you can measure”\n\n\nCitationBibTeX citation:@online{brophy2024,\n  author = {Brophy, Jay},\n  title = {Does It Make a Difference - Sedentary Break},\n  date = {2024-03-05},\n  url = {https://brophyj.github.io/posts/2024-02-19-my-blog-post/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nBrophy, Jay. 2024. “Does It Make a Difference - Sedentary\nBreak.” March 5, 2024. https://brophyj.github.io/posts/2024-02-19-my-blog-post/."
  },
  {
    "objectID": "posts/2024-02-12-endotoxin-exposure-in-asthmatic-children-and-matched-healthy-controls/index.html",
    "href": "posts/2024-02-12-endotoxin-exposure-in-asthmatic-children-and-matched-healthy-controls/index.html",
    "title": "Endotoxin exposure in asthmatic children and matched healthy controls",
    "section": "",
    "text": "Background\nRecall that the goal of the course is to not only improve critical appraisal skills but also to think about research questions, designs, and the necessary compromises that are often required in research. Hopefully this adds another dimension to typical journal clubs where either an article in uncritically endorsed enthusiastically or trashed unmercifully, although this is sometimes quite merited For reasons I am somewhat unclear about, this week’s selected article was the 2005 publication Endotoxin exposure in asthmatic children and matched healthy controls: results of IPEADAM study. Although not described as such, this was apparently a nested case-control study from a 1999 crosssectional study by the same authors, of over 1500 completed questionnaires. Cases were children between the ages of 4 and 17 who had a study diagnosis of probable asthma. These asthmatic children were matched for sex, age and sib-ship size with children living in asthma free households and the following main conclusions reported. \n\n\n\n\n\nA critical analysis should consider bias and statistical issues\nBiases\nIt is helpful to consider biases in observational studies according to the following grouping\n- selection\n- misinformation\n- confounding\nSelection bias\nSelection bias is a distortion in the measure of association due to a sample selection such the measured association is not representative of what exists in the target population.\nIf the selection of cases and controls is not done independently of the exposure, then when you compare exposure distributions any observed differences are a combination of a true effect and an artifact of the way the data was collected.\nThis figure may help explain. Where would you put the reinforcements?\n\n\n\n\n\n\n\n\n\nAfter identification of the research question, the next step is to distinguish among the various populations, including the\n- target population (all children in the UK)\n- study population (all those with a chance of being in the study, ie the 1500 children who completed the original questionnaire)\n- sample population (the 200 children in Figure 1)\n- analyzed sample population (the 90 matched pairs of children)\nIn their previous work, the authors report an asthma prevalence of approximately 20%, or about 300 children based on their study population of 1500. The following questions need answering.\n- Does the study population (?1500) reflect the target population?\n- Do the 200 sample children reflect the total study population ?\n- Do the 90 matched pairs, the analytical sample population reflect the overall sample population? What about the missing cases?Many reasons to be concerned about possible selection bias in this study.\nLet’s begin by examining their Figure 1 which is reproduced below. \n\n\n\n\n\n\n\n\n\nHow many asthma cases (and controls) did they identify in this Figure?\nThe figure shows 105 cases and 93 controls, a total of 198 children. Yet the authors claim this figure shows the age distribution of 200 children. While the difference is small, it does raise further concerns about the reliability of their data analysis when there is a discordance in a simple counting of individuals.\nWhy do they only use 90 cases? Presumably to meet their matching criteria, age (+/- 1 year). Below is the best matching I could create from their data.\n\n\n\n\n\n\n\n\n\nThe question then becomes why match?\nMost people think matching is to control for confounding but this is only partly true (and indeed may be more than offset by potential selection bias) and the best reason is to improve precision in situations of sparse data.\nMoreover, in this case a better alternative would have been not to match but to control for age in regression analysis as this would have allowed an estimation of the effect of age on the detection of asthma, while using the whole study sample of 198 children, including all 105 cases.\nPerforming logistic regression glm(stat~ages, data = data_long_uncount, family = \"binomial\") shows that each year of additional age is associated with a odds ration decrease in asthma diagnosis = OR = 0.92, 95%CI 0.89 - 0.96\nMisclassification\nThe authors don’t report the raw data for the endotoxin exposure but assuming the following distribution among cases and controls gives an OR that approximates their results\n\n\n--Observed data-- \n         Outcome: Exposed+ \n       Comparing: Cases vs. Controls \n\n         Cases Controls\nExposed+    40       50\nExposed-    27       63\n\n                            2.5% 97.5%\nObserved Relative Risk: 1.3  1.0   1.8\n   Observed Odds Ratio: 1.9  1.0   3.4\n---\n                                                   \nMisclassification Bias Corrected Relative Risk: 1.3\n   Misclassification Bias Corrected Odds Ratio: 1.9\n\n\nAs the authors report from their previous work that their asthma detection questionnaire has only a 70% sensitivity and 91% specificity misclassification is present.\nThe effect of misclassification can be quantified using quantitative bias analysis (QBA) via the episensr package and misclassification function. This seems an improvement over purely qualitative heuristics, such as “non-differential misclassification biases toward the null”.\n\nCodelibrary(episensr)\nmisclassification(matrix(c(40, 50, 27, 63),\n                          dimnames = list(c(\"Exposed+\", \"Exposed-\"), c(\"Cases\", \"Controls\")),\n                         nrow = 2, byrow = TRUE),\n                  type = \"outcome\",\n                  bias_parms = c(.70,.70,.91,.91))\n\n--Observed data-- \n         Outcome: Exposed+ \n       Comparing: Cases vs. Controls \n\n         Cases Controls\nExposed+    40       50\nExposed-    27       63\n\n                            2.5% 97.5%\nObserved Relative Risk: 1.3  1.0   1.8\n   Observed Odds Ratio: 1.9  1.0   3.4\n---\n                                                   \nMisclassification Bias Corrected Relative Risk: 1.4\n   Misclassification Bias Corrected Odds Ratio: 3.6\n\n\nConceptually, this misclassification of cases and controls suggest any association between indoor air pollutants and asthma will likely be underestimated and this analysis permits an estimate of the order of magnitude.\nConfounding\nHow much residual or unmeasured confounding would be required to wipe out the observed effect? This can be determined using the EValue package as described in this paper.\n\n\n         point lower upper\nRR         1.4   1.1   1.8\nE-values   2.1   1.3    NA\n\n\nThis suggests that a moderate confounder with a risk of 2.1 fold to exposure and a 2.1 fold increase in the outcome would be required to eliminate the observed risk. Of course if the true OR is greater due to misclassification bias the size of unmeasured confounder needed to eradicate the observed association would be even larger.\nIn conclusion, there are multiple potential biases (selection, misclassification and confounding) associated with this study. Unmeasured confounding is unlikely to explain the observed association and misclassification suggest the association may be underestimated, but the inability to evaluate the magnitude and direction of the selection bias limits definitive determination of the overall direction of the bias assessment.\nAnalyses\nThe authors they performed a logistic regression where presumably probable asthma is the dependent variable. In this case understanding their table 2 is difficult.\n\n\n\n\n\n From Table 2 the authors make causal statements not only about endotoxins and asthma but also about other variables, including for example, dampness and single parent home.\nMaking assertions based on regression coefficients from a multivariable analysis is subject to Table 2 Fallacy. These covariate effect estimates may also be confounded even though the effect estimate for the main exposure is not confounded and their proper interpretation far from obvious. The authors state “There was no difference in the levels of exposure to house dust major allergen Der p 1, expressed in quartiles of exposure between asthmatic and non-asthmatic matched controls (Table 3)”\n\n\n\n\n\n Looking at the confidence intervals we see they are very wide and, for example, don’t exclude that for quartile 2 there is a 180% increase or 64% decrease in asthma prevalence compared to quartile 1. The authors have conflated “an absence of evidence with evidence of absence”. Aslo see this previous post.\nThe authors make the same error in Table 4\n\n\n\n\n\n when they conclude there are no interactions. The more reasonable conclusion being even if one ignores the potential biases, they lack sufficient power to draw conclusions about interactions.\nConclusion\nA critical appraisal of this publication has shown several interesting avenues for discussion, perhaps explaining why it was suggested for review. Based on the critical appraisal it would seem there is little to support their original conclusions.\n\n\nCitationBibTeX citation:@online{brophy2024,\n  author = {Brophy, Jay},\n  title = {Endotoxin Exposure in Asthmatic Children and Matched Healthy\n    Controls},\n  date = {2024-02-19},\n  url = {https://brophyj.github.io/posts/2024-02-19-my-blog-post/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nBrophy, Jay. 2024. “Endotoxin Exposure in Asthmatic Children and\nMatched Healthy Controls.” February 19, 2024. https://brophyj.github.io/posts/2024-02-19-my-blog-post/."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "James (Jay) Brophy",
    "section": "",
    "text": "James (Jay) Brophy is a tenured (full) professor with a joint appointment in the Departments of Medicine and Epidemiology and Biostatistics at McGill University. He is a cardiologist and does research in cardiovascular epidemiology. His research interests are eclectic and include outcomes research, pharmacoepidemiology, Bayesian statistics, health technology assessment, economic analyses and clinical research. He held a FRQS chair in health technology assessment and evidence-based medicine (2008-2023).\n He is a fellow of the Canadian Academy of Health Sciences and the Canadian Cardiovascular Society.\nHave a look at my  curriculum vitae"
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "James (Jay) Brophy",
    "section": "Education",
    "text": "Education\n\nPhD Epidemiology & biostatistics - McGill University\n\nCardiology / Internal medicine - Université de Montreal\n\nMD - McMaster University\n\nM.Eng - McMaster University\n\nB.Eng - McGill University"
  },
  {
    "objectID": "index.html#interests",
    "href": "index.html#interests",
    "title": "James (Jay) Brophy",
    "section": "Interests",
    "text": "Interests\n\nCardiovascular medicine & epidemiology\nBayesian statistics\nEvidence based medicine\nData analysis & visualization\nKnowledge sharing\nMedical decision-making"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "Does it make a difference - sedentary break\n\n\n\n\n\n\n\nbias\n\n\nstats\n\n\n\n\nWhat counts?\n\n\n\n\n\n\nTuesday, the 5th of March, 2024\n\n\nJay Brophy\n\n\n\n\n\n\n  \n\n\n\n\nEndotoxin exposure in asthmatic children and matched healthy controls\n\n\n\n\n\n\n\nbias\n\n\nmisclassification\n\n\nselection bias\n\n\n\n\nWhat counts?\n\n\n\n\n\n\nMonday, the 19th of February, 2024\n\n\nJay Brophy\n\n\n\n\n\n\nNo matching items"
  }
]